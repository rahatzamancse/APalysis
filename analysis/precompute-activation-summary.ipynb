{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 16:34:28.848190: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-19 16:34:28.848213: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-19 16:34:28.849059: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-19 16:34:28.853725: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-19 16:34:29.468792: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/insane/.cache/pypoetry/virtualenvs/apalysis-5kmHI_dQ-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Num CPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 16:34:31.281015: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-19 16:34:31.296171: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-19 16:34:31.296388: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.dirname('/home/insane/u/APalysis/analysis'))\n",
    "\n",
    "import keract\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "from nltk.corpus import wordnet as wn\n",
    "from tensorflow import keras as K\n",
    "from tqdm import tqdm\n",
    "from analysis import metrics\n",
    "import utils\n",
    "\n",
    "# check if using GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.experimental.list_physical_devices('CPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.inception_v3.InceptionV3( weights='imagenet')\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "ds, info = tfds.load(\n",
    "    'imagenet2012',\n",
    "    shuffle_files=False,\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    "    batch_size=None,\n",
    "    data_dir='/run/media/insane/Games/Tensorflow/tensorflow_datasets'\n",
    ")\n",
    "labels = list(map(lambda l: wn.synset_from_pos_and_offset(\n",
    "        l[0], int(l[1:])).name(), info.features['label'].names))\n",
    "ds = ds['train']\n",
    "\n",
    "\n",
    "inception_input_shape = tf.keras.applications.inception_v3.InceptionV3().input.shape[1:3].as_list()\n",
    "@tf.function\n",
    "def preprocess(x, y):\n",
    "    x = tf.image.resize(x, inception_input_shape, method=tf.image.ResizeMethod.BILINEAR)\n",
    "    x = tf.keras.applications.inception_v3.preprocess_input(x)\n",
    "    return x, y\n",
    "\n",
    "def preprocess_inv(x, y):\n",
    "    x = ((x / 2 + 0.5) * 255).astype(np.uint8).squeeze()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw barchart on how many images per class is there in imagenet\n",
    "label_counts = np.zeros(len(labels))\n",
    "for x, y in tqdm(ds):\n",
    "    label_counts[y] += 1\n",
    "total = np.sum(label_counts)\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "plt.bar(labels, label_counts)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dict_numpy(d):\n",
    "    '''Prints a dictionary with numpy arrays recursively. Numpy arrays are printed as their shape and dtype.'''\n",
    "    if not isinstance(d, dict):\n",
    "        print(d)\n",
    "        return\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            print(k, \":\", end=\" \")\n",
    "            print_dict_numpy(v)\n",
    "        elif isinstance(v, np.ndarray):\n",
    "            print(k, \":\", v.shape, v.dtype)\n",
    "        else:\n",
    "            print(k, \":\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/699 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 16:35:13.117759: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-03-19 16:35:13.388780: W external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:504] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  /usr/local/cuda-12.2\n",
      "  /usr/local/cuda\n",
      "  /home/insane/.cache/pypoetry/virtualenvs/apalysis-5kmHI_dQ-py3.10/lib/python3.10/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc\n",
      "  /home/insane/.cache/pypoetry/virtualenvs/apalysis-5kmHI_dQ-py3.10/lib/python3.10/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "  3%|▎         | 19/699 [13:52<8:04:38, 42.76s/it]2024-03-19 16:49:00.098901: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 1073152 bytes after encountering the first element of size 1073152 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "  3%|▎         | 22/699 [17:50<13:05:09, 69.59s/it]"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "summary_fn_image = metrics.summary_fn_image_l2\n",
    "summary_fn_dense = metrics.summary_fn_dense_identity\n",
    "\n",
    "layers = list(map(lambda layer: layer.name, filter(lambda l: isinstance(l, (\n",
    "    # K.layers.InputLayer,\n",
    "    K.layers.Conv2D,\n",
    "    # K.layers.Dense,\n",
    "    # K.layers.Flatten,\n",
    "    K.layers.Concatenate,\n",
    ")), model.layers)))\n",
    "\n",
    "labels_so_far = np.zeros(len(labels), dtype=np.int32)\n",
    "MAX_COUNT = 100\n",
    "layers_to_save = ['mixed10', 'mixed9', 'mixed7']\n",
    "# layers_to_save = layers\n",
    "\n",
    "for class_label in tqdm(range(301, 1000)):\n",
    "    # __datasetImgs = [[] for _ in range(len(labels))]\n",
    "    # __activations = [[] for _ in range(len(labels))]\n",
    "    __activationsSummary = {k: [] for k in layers_to_save}\n",
    "    # __datasetLabels = []\n",
    "    dataset = ds.map(preprocess).batch(BATCH_SIZE).shuffle(1000)\n",
    "    # printed = False\n",
    "    for i, (img, label) in enumerate(dataset):\n",
    "        if label.numpy().item() != class_label:\n",
    "            continue\n",
    "\n",
    "        # if not printed:\n",
    "        #     print(\"Class :\", label.numpy().item())\n",
    "        #     plt.imshow(img[0])\n",
    "        #     plt.show()\n",
    "        #     printed = True\n",
    "\n",
    "        # Get activations\n",
    "        activation = keract.get_activations(\n",
    "            model, img, layer_names=layers_to_save, nodes_to_evaluate=None, output_format='simple', nested=False, auto_compile=True)\n",
    "\n",
    "        activationSummary = {}\n",
    "        for layer, v in activation.items():\n",
    "            if layer not in layers_to_save: continue\n",
    "            if len(v[0].shape) == 1:\n",
    "                # dense layer\n",
    "                activationSummary[layer] = summary_fn_dense(v)\n",
    "            elif len(v[0].shape) == 3:\n",
    "                # Image layer\n",
    "                activationSummary[layer] = summary_fn_image(v)\n",
    "                \n",
    "        # labels_so_far[label.numpy()] += 1\n",
    "        # __datasetLabels += label.numpy().tolist()\n",
    "        \n",
    "        for layer, summary in activationSummary.items():\n",
    "            if layer not in layers_to_save: continue\n",
    "            __activationsSummary[layer] += summary.tolist()\n",
    "            \n",
    "        if layers_to_save[0] in __activationsSummary and len(__activationsSummary[layers_to_save[0]]) >= MAX_COUNT:\n",
    "            break\n",
    "            \n",
    "            \n",
    "    # datasetImgs = [j for i in __datasetImgs for j in i]\n",
    "    # activations = [j for i in __activations for j in i]\n",
    "    activationsSummary = {k: np.array(v) for k, v in __activationsSummary.items()}\n",
    "    # datasetLabels = np.array(__datasetLabels)\n",
    "    \n",
    "    # save the activation summary\n",
    "    np.savez_compressed(f'./activation_summary/activations_{class_label}.npz', **activationsSummary)\n",
    "    \n",
    "# Get the prediction with argmax\n",
    "# predictions = []\n",
    "# for i in range(len(activations)):\n",
    "#     predictions.append(np.argmax(activations[i][layers[-1]][0]).item())\n",
    "\n",
    "print_dict_numpy(activationsSummary)\n",
    "# print(datasetLabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
