{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not Enabled\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import keract\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "\n",
    "with_gpu = True\n",
    "if not with_gpu:\n",
    "    tf.config.experimental.set_visible_devices([], \"GPU\")\n",
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    print(\"GPU is Enabled\")\n",
    "else:\n",
    "    print(\"GPU is not Enabled\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and preprocess ImageNet dataset\n",
    "def preprocess(img, label):\n",
    "    img = tf.image.resize(img, (224, 224))\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = tf.keras.applications.vgg16.preprocess_input(img)\n",
    "    return img, label\n",
    "\n",
    "ds_train = tfds.load(\n",
    "    'imagenet2012',\n",
    "    split='train',\n",
    "    as_supervised=True,\n",
    "    data_dir='/home/insane/U/NN Activation/imagenet'\n",
    ")\n",
    "\n",
    "ds_train = ds_train.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_test = tfds.load(\n",
    "    'imagenet2012',\n",
    "    split='validation',\n",
    "    as_supervised=True,\n",
    "    data_dir='/home/insane/U/NN Activation/imagenet'\n",
    ")\n",
    "\n",
    "ds_test = ds_test.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(32).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the model BEFORE applying pruning\n",
    "base_model = tf.keras.applications.VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "base_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magnitude-based Weight Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/insane/.cache/pypoetry/virtualenvs/channelexplorer-ajWhp0a7-py3.10/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/insane/.cache/pypoetry/virtualenvs/channelexplorer-ajWhp0a7-py3.10/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "100/100 [==============================] - 650s 6s/step - loss: 7.2837 - accuracy: 9.3750e-04\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 648s 6s/step - loss: 6.9076 - accuracy: 0.0016\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pruned_vgg16_savedmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pruned_vgg16_savedmodel/assets\n"
     ]
    }
   ],
   "source": [
    "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = tf.keras.layers.Dense(1000, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Step 3: Apply pruning wrapper BEFORE compiling or calling the model\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "        initial_sparsity=0.0,\n",
    "        final_sparsity=0.5,\n",
    "        begin_step=0,\n",
    "        end_step=10000\n",
    "    )\n",
    "}\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# Step 4: Compile the model\n",
    "model_for_pruning.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Step 5: Train with pruning callback\n",
    "callbacks = [tfmot.sparsity.keras.UpdatePruningStep()]\n",
    "model_for_pruning.fit(\n",
    "    ds_train,\n",
    "    epochs=2,\n",
    "    steps_per_epoch=100,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "\n",
    "# Save the pruned model\n",
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "# Or save in TensorFlow SavedModel format\n",
    "model_for_export.save('pruned_vgg16_savedmodel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 407s 4s/step - loss: 6.9168 - accuracy: 6.2500e-04\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 390s 4s/step - loss: 6.9080 - accuracy: 3.1250e-04\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 376s 4s/step - loss: 6.9079 - accuracy: 9.3750e-04\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 380s 4s/step - loss: 6.9078 - accuracy: 0.0012\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 387s 4s/step - loss: 6.9087 - accuracy: 0.0012\n"
     ]
    }
   ],
   "source": [
    "conv_layers = [layer for layer in base_model.layers if isinstance(layer, tf.keras.layers.Conv2D)]\n",
    "\n",
    "def l1_norm_filter_selection(weights, percent=0.3):\n",
    "    \"\"\"\n",
    "    Select filter indices to keep based on L1-norm pruning.\n",
    "    \"\"\"\n",
    "    filter_weights = weights[0]  # shape: (H, W, in_channels, out_channels)\n",
    "    l1_norms = np.sum(np.abs(filter_weights), axis=(0, 1, 2))  # L1-norm per filter\n",
    "    num_filters = filter_weights.shape[-1]\n",
    "    num_prune = int(percent * num_filters)\n",
    "    keep_indices = np.argsort(l1_norms)[num_prune:]  # keep the highest ones\n",
    "    return keep_indices\n",
    "\n",
    "def prune_conv_weights(weights, input_keep_indices, output_keep_indices):\n",
    "    \"\"\"\n",
    "    Prune weights based on selected input and output channel indices.\n",
    "    \"\"\"\n",
    "    W, b = weights\n",
    "    # Prune input channels (axis=2) and output filters (axis=3)\n",
    "    W = W[:, :, input_keep_indices, :]\n",
    "    W = W[:, :, :, output_keep_indices]\n",
    "    b = b[output_keep_indices]\n",
    "    return [W, b]\n",
    "\n",
    "def build_pruned_model(percent=0.3):\n",
    "    input_tensor = tf.keras.layers.Input(shape=(224, 224, 3))\n",
    "    x = input_tensor\n",
    "\n",
    "    previous_keep_indices = np.arange(3)  # RGB input\n",
    "\n",
    "    pruned_weights = []\n",
    "    keep_indices_list = []\n",
    "\n",
    "    # Analyze pruning first\n",
    "    for layer in conv_layers:\n",
    "        orig_weights = layer.get_weights()\n",
    "        if not orig_weights:\n",
    "            continue\n",
    "        output_keep_indices = l1_norm_filter_selection(orig_weights, percent)\n",
    "        keep_indices_list.append((previous_keep_indices, output_keep_indices))\n",
    "        pruned_w = prune_conv_weights(orig_weights, previous_keep_indices, output_keep_indices)\n",
    "        pruned_weights.append(pruned_w)\n",
    "        previous_keep_indices = output_keep_indices\n",
    "\n",
    "    # Build new model\n",
    "    layer_idx = 0\n",
    "    previous_filters = 3\n",
    "    previous_keep_indices = np.arange(3)\n",
    "    for layer in base_model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            in_idx, out_idx = keep_indices_list[layer_idx]\n",
    "            filters = len(out_idx)\n",
    "            x = tf.keras.layers.Conv2D(\n",
    "                filters=filters,\n",
    "                kernel_size=layer.kernel_size,\n",
    "                strides=layer.strides,\n",
    "                padding=layer.padding,\n",
    "                activation=layer.activation,\n",
    "                name=f\"pruned_conv_{layer_idx}\"\n",
    "            )(x)\n",
    "            layer_idx += 1\n",
    "        elif isinstance(layer, tf.keras.layers.MaxPooling2D):\n",
    "            x = tf.keras.layers.MaxPooling2D(pool_size=layer.pool_size, strides=layer.strides, padding=layer.padding)(x)\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(1000, activation='softmax')(x)\n",
    "    pruned_model = tf.keras.Model(inputs=input_tensor, outputs=x)\n",
    "\n",
    "    # Set pruned weights\n",
    "    conv_idx = 0\n",
    "    for layer in pruned_model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            layer.set_weights(pruned_weights[conv_idx])\n",
    "            conv_idx += 1\n",
    "\n",
    "    return pruned_model\n",
    "\n",
    "# Build and compile the pruned model\n",
    "pruned_model = build_pruned_model(percent=0.3)\n",
    "pruned_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "pruned_model.fit(ds_train, epochs=5, steps_per_epoch=100)\n",
    "\n",
    "\n",
    "# Save the pruned model\n",
    "pruned_model.save(\"vgg16_filter_pruned.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:\n",
      "Base model: 138,357,544\n",
      "Weight pruned model: 7,601,979\n",
      "Filter pruned model: 15,227,688\n",
      "\n",
      "Evaluating models on test data...\n",
      "\n",
      "Test Performance:\n",
      "Base model - Loss: 1.4519, Accuracy: 0.6600\n",
      "Weight pruned model - Loss: 6.9082, Accuracy: 0.0044\n",
      "Filter pruned model - Loss: 6.9087, Accuracy: 0.0012\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.vgg16.VGG16(weights='imagenet')\n",
    "base_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Load the original and pruned models for comparison\n",
    "weight_pruned_model = tf.keras.models.load_model(\"../../saved models/vgg16_filter_pruned.h5\")\n",
    "weight_pruned_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "filter_pruned_model = tf.keras.models.load_model(\"../../saved models/pruned_vgg16_savedmodel\")\n",
    "filter_pruned_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Compare number of parameters\n",
    "print(\"Number of parameters:\")\n",
    "print(f\"Base model: {base_model.count_params():,}\")\n",
    "print(f\"Weight pruned model: {weight_pruned_model.count_params():,}\")\n",
    "print(f\"Filter pruned model: {filter_pruned_model.count_params():,}\")\n",
    "\n",
    "print(\"\\nEvaluating models on test data...\")\n",
    "\n",
    "# Evaluate models on test data\n",
    "base_results = base_model.evaluate(ds_test, steps=50, verbose=0)\n",
    "weight_pruned_results = weight_pruned_model.evaluate(ds_test, steps=50, verbose=0)\n",
    "filter_pruned_results = filter_pruned_model.evaluate(ds_test, steps=50, verbose=0)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Base model - Loss: {base_results[0]:.4f}, Accuracy: {base_results[1]:.4f}\")\n",
    "print(f\"Weight pruned model - Loss: {weight_pruned_results[0]:.4f}, Accuracy: {weight_pruned_results[1]:.4f}\")\n",
    "print(f\"Filter pruned model - Loss: {filter_pruned_results[0]:.4f}, Accuracy: {filter_pruned_results[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "channelexplorer-ajWhp0a7-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
